{"cells":[{"cell_type":"code","source":["# Libraries\n\nimport numpy as np\nfrom statsmodels.tsa.arima_model import ARIMA\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom numpy import log\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["%scala \nval driver = \"org.postgresql.Driver\"\nval jdbcUsername = \"data_sci\"\nval jdbcPassword = \"dataSci4lyf\"\n\n\n\nval jdbcUrl = \"jdbc:postgresql://cpdb-databricks.cgod7egsd6vr.us-east-2.rds.amazonaws.com/cpdb\"\n\nimport java.util.Properties\nval connectionProperties = new Properties()\n\nconnectionProperties.put(\"user\", jdbcUsername)\nconnectionProperties.put(\"password\", jdbcPassword)\nconnectionProperties.setProperty(\"Driver\", driver)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">driver: String = org.postgresql.Driver\njdbcUsername: String = data_sci\njdbcPassword: String = dataSci4lyf\njdbcUrl: String = jdbc:postgresql://cpdb-databricks.cgod7egsd6vr.us-east-2.rds.amazonaws.com/cpdb\nimport java.util.Properties\nconnectionProperties: java.util.Properties = {user=data_sci, password=dataSci4lyf, Driver=org.postgresql.Driver}\nres5: Object = null\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["%scala \nval data_officer_sql = \"(select * from data_officer) doc_tags\"\nval data_officer = spark.read.jdbc(url=jdbcUrl, table=data_officer_sql, properties=connectionProperties)\ndata_officer.createOrReplaceTempView(\"data_officer\")\n\nval data_officerallegation_sql = \"(select * from data_officerallegation) doc_tags\"\nval data_officerallegation = spark.read.jdbc(url=jdbcUrl, table=data_officerallegation_sql, properties=connectionProperties)\ndata_officerallegation.createOrReplaceTempView(\"data_officerallegation\")\n\nval data_allegation_sql = \"(select * from data_allegation) doc_tags\"\nval data_allegation = spark.read.jdbc(url=jdbcUrl, table=data_allegation_sql, properties=connectionProperties)\ndata_allegation.createOrReplaceTempView(\"data_allegation\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">data_officer_sql: String = (select * from data_officer) doc_tags\ndata_officer: org.apache.spark.sql.DataFrame = [id: int, gender: string ... 17 more fields]\ndata_officerallegation_sql: String = (select * from data_officerallegation) doc_tags\ndata_officerallegation: org.apache.spark.sql.DataFrame = [id: int, start_date: date ... 11 more fields]\ndata_allegation_sql: String = (select * from data_allegation) doc_tags\ndata_allegation: org.apache.spark.sql.DataFrame = [id: int, crid: string ... 11 more fields]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["\n\n# Create training, testing and predict sets\n\ndata_training = spark.sql('select cast(CONCAT(extract(year from data_allegation.incident_date), extract(month from data_allegation.incident_date) + 10) as int) as id_, count(data_officerallegation.id) as count_, CONCAT(extract(month from data_allegation.incident_date), \"/01/\", extract(year from data_allegation.incident_date)) as date from data_officerallegation inner join data_allegation on data_officerallegation.allegation_id = data_allegation.id where data_allegation.incident_date is not null group by id_, date having id_ >= 200000 and id_ < 201400 order by id_ ').toPandas() \n\ndata_training = data_training.set_index('date')\n\ndata_testing = spark.sql('select cast(CONCAT(extract(year from data_allegation.incident_date), extract(month from data_allegation.incident_date) + 10) as int) as id_, count(data_officerallegation.id) as count_, CONCAT(extract(month from data_allegation.incident_date), \"/01/\", extract(year from data_allegation.incident_date)) as date from data_officerallegation inner join data_allegation on data_officerallegation.allegation_id = data_allegation.id where data_allegation.incident_date is not null group by id_, date having id_ >= 201400 and id_ < 201500 order by id_').toPandas()\n \ndata_testing = data_testing.set_index('date')\n\ndata_predict = spark.sql('select cast(CONCAT(extract(year from data_allegation.incident_date), extract(month from data_allegation.incident_date) + 10) as int) as id_, count(data_officerallegation.id) as count_, CONCAT(extract(month from data_allegation.incident_date), \"/01/\", extract(year from data_allegation.incident_date)) as date from data_officerallegation inner join data_allegation on data_officerallegation.allegation_id = data_allegation.id where data_allegation.incident_date is not null group by id_, date having id_ >= 201500 order by id_').toPandas()\n\ndata_predict = data_predict.set_index('date')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/pyarrow/__init__.py:152: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n  warnings.warn(&#34;pyarrow.open_stream is deprecated, please use &#34;\n/databricks/python/lib/python3.7/site-packages/pyarrow/__init__.py:152: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n  warnings.warn(&#34;pyarrow.open_stream is deprecated, please use &#34;\n/databricks/python/lib/python3.7/site-packages/pyarrow/__init__.py:152: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n  warnings.warn(&#34;pyarrow.open_stream is deprecated, please use &#34;\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Drop columns which are not needed\ndata_training = data_training.drop(['id_'], axis=1)\ndata_testing = data_testing.drop(['id_'], axis=1)\ndata_predict = data_predict.drop(['id_'], axis=1)\nprint(data_training)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">            count_\ndate              \n1/01/2000     1710\n2/01/2000     1670\n3/01/2000     1753\n4/01/2000     1672\n5/01/2000     1519\n6/01/2000     1700\n7/01/2000     1758\n8/01/2000     1973\n9/01/2000     1586\n10/01/2000    1680\n11/01/2000    1276\n12/01/2000    1143\n1/01/2001     1380\n2/01/2001     1009\n3/01/2001     1202\n4/01/2001     1069\n5/01/2001      952\n6/01/2001     1045\n7/01/2001     1072\n8/01/2001     1046\n9/01/2001      927\n10/01/2001     865\n11/01/2001     966\n12/01/2001     789\n1/01/2002      964\n2/01/2002      839\n3/01/2002      937\n4/01/2002      938\n5/01/2002     1060\n6/01/2002     1085\n...            ...\n7/01/2011      525\n8/01/2011      597\n9/01/2011      514\n10/01/2011     570\n11/01/2011     462\n12/01/2011     417\n1/01/2012      383\n2/01/2012      422\n3/01/2012      479\n4/01/2012      505\n5/01/2012      483\n6/01/2012      546\n7/01/2012      530\n8/01/2012      559\n9/01/2012      445\n10/01/2012     429\n11/01/2012     345\n12/01/2012     403\n1/01/2013      430\n2/01/2013      349\n3/01/2013      457\n4/01/2013      556\n5/01/2013      529\n6/01/2013      419\n7/01/2013      445\n8/01/2013      500\n9/01/2013      423\n10/01/2013     397\n11/01/2013     446\n12/01/2013     301\n\n[168 rows x 1 columns]\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["print(data_training.index)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Index([&#39;1/01/2000&#39;, &#39;2/01/2000&#39;, &#39;3/01/2000&#39;, &#39;4/01/2000&#39;, &#39;5/01/2000&#39;,\n       &#39;6/01/2000&#39;, &#39;7/01/2000&#39;, &#39;8/01/2000&#39;, &#39;9/01/2000&#39;, &#39;10/01/2000&#39;,\n       ...\n       &#39;3/01/2013&#39;, &#39;4/01/2013&#39;, &#39;5/01/2013&#39;, &#39;6/01/2013&#39;, &#39;7/01/2013&#39;,\n       &#39;8/01/2013&#39;, &#39;9/01/2013&#39;, &#39;10/01/2013&#39;, &#39;11/01/2013&#39;, &#39;12/01/2013&#39;],\n      dtype=&#39;object&#39;, name=&#39;date&#39;, length=168)\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# ADF test to check stationarity\n# If p value < 0.05 then stationary else take the differenciation\n\nresult = adfuller(data_training.count_.dropna())\nprint('p-value: %f' % result[1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">p-value: 0.039865\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# finding order of AR term using partial autocorrelation plot\n\nfig, axes = plt.subplots(1, 1)\naxes.set(ylim=(0,5))\nplot_pacf(data_training.count_.diff().dropna(), ax=axes)\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# finding order of AR term using autocorrelation plot\n\nfig, axes = plt.subplots(1, 1)\naxes.set(ylim=(0,5))\nplot_acf(data_training.count_.dropna(), ax=axes)\n\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["model = ARIMA(data_training.count_, order=(9,0,3))\nresults = model.fit(disp=0)\nprint(results.summary())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n  % freq, ValueWarning)\n                              ARMA Model Results                              \n==============================================================================\nDep. Variable:                 count_   No. Observations:                  168\nModel:                     ARMA(9, 3)   Log Likelihood               -1006.317\nMethod:                       css-mle   S.D. of innovations             93.462\nDate:                Thu, 12 Dec 2019   AIC                           2040.634\nTime:                        05:13:57   BIC                           2084.369\nSample:                    01-01-2000   HQIC                          2058.384\n                         - 12-01-2013                                         \n================================================================================\n                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------\nconst          570.3173   5665.938      0.101      0.920   -1.05e+04    1.17e+04\nar.L1.count_     1.6725      0.270      6.189      0.000       1.143       2.202\nar.L2.count_    -0.6551      0.523     -1.252      0.212      -1.680       0.370\nar.L3.count_    -0.4799      0.339     -1.415      0.159      -1.144       0.185\nar.L4.count_     0.1849      0.172      1.072      0.285      -0.153       0.523\nar.L5.count_     0.4091      0.179      2.286      0.024       0.058       0.760\nar.L6.count_    -0.1197      0.188     -0.638      0.525      -0.487       0.248\nar.L7.count_    -0.1004      0.176     -0.572      0.568      -0.445       0.244\nar.L8.count_    -0.1062      0.159     -0.667      0.506      -0.418       0.206\nar.L9.count_     0.1915      0.096      2.004      0.047       0.004       0.379\nma.L1.count_    -1.2441      0.272     -4.577      0.000      -1.777      -0.711\nma.L2.count_     0.6447      0.401      1.609      0.110      -0.141       1.430\nma.L3.count_     0.2392      0.267      0.897      0.371      -0.283       0.762\n                                    Roots                                    \n=============================================================================\n                  Real          Imaginary           Modulus         Frequency\n-----------------------------------------------------------------------------\nAR.1           -1.2059           -0.5477j            1.3244           -0.4321\nAR.2           -1.2059           +0.5477j            1.3244            0.4321\nAR.3           -0.6294           -1.2831j            1.4292           -0.3226\nAR.4           -0.6294           +1.2831j            1.4292            0.3226\nAR.5            0.6576           -0.8707j            1.0911           -0.1471\nAR.6            0.6576           +0.8707j            1.0911            0.1471\nAR.7            0.9535           -0.5584j            1.1050           -0.0843\nAR.8            0.9535           +0.5584j            1.1050            0.0843\nAR.9            1.0028           -0.0000j            1.0028           -0.0000\nMA.1            0.7419           -0.6707j            1.0002           -0.1170\nMA.2            0.7419           +0.6707j            1.0002            0.1170\nMA.3           -4.1788           -0.0000j            4.1788           -0.5000\n-----------------------------------------------------------------------------\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["#predictions for the year 2014\n\npred = results.forecast(12)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["fig, ax = plt.subplots(1,1, figsize = (13,5))\nplt.plot( data_testing.index, pred[0])\nplt.plot( data_testing.index,data_testing.count_)\nplt.legend(['pred','actual'])\nplt.xlabel('Date')\nplt.ylabel('No. of allegations')\nplt.title('Predictions on 2014')\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["print(\"score for 2014 data\",r2_score(data_testing.count_,pred[0] ))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">score for 2014 data -0.29008373357349226\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# Predictions for year 2015\n\npred2 = results.forecast(12)\nfig, ax = plt.subplots(1,1, figsize = (13,5))\nplt.plot( data_predict.index[:11], pred2[0][:11])\nplt.plot( data_predict.index[:11],data_predict.count_[:11])\nplt.legend(['pred','actual'])\nplt.xlabel('Date')\nplt.ylabel('No. of allegations')\nplt.title('Predictions on 2015')\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["print(\"score for 2015 data\", r2_score(data_predict.count_[:11],pred2[0][:11]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">score for 2015 data -1.8144730948223144\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"CP5Q2","notebookId":4281434282507131},"nbformat":4,"nbformat_minor":0}
